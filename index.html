<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="description" content="" />
  <title>MimicDroid</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />
  <link rel="stylesheet" href="./static/css/bulma.min.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@glidejs/glide@3.6.0/dist/css/glide.core.min.css" />
  <link rel="stylesheet" href="./static/css/index.css" />
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">

  <!-- Custom styles for Navigation and Enhanced Design -->
  <style>
    /* Navigation Bar Styles */
    .navbar {
      background: linear-gradient(135deg, rgba(255,255,255,0.95) 0%, rgba(249,250,251,0.95) 100%);
      backdrop-filter: blur(10px);
      box-shadow: 0 2px 20px rgba(0,0,0,0.08);
      padding: 0.75rem 0;
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      z-index: 100;
      transition: all 0.3s ease;
      border-bottom: 1px solid rgba(102, 126, 234, 0.1);
    }

    .navbar.scrolled {
      background: linear-gradient(135deg, rgba(255,255,255,0.98) 0%, rgba(249,250,251,0.98) 100%);
      box-shadow: 0 4px 30px rgba(0,0,0,0.12);
      padding: 0.5rem 0;
    }

    .navbar-brand {
      font-weight: 700;
      font-size: 1.5rem;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      background-clip: text;
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      transition: all 0.3s ease;
    }

    .navbar-brand:hover {
      transform: translateX(5px);
    }

    .navbar-menu {
      background: transparent;
    }

    .navbar-item {
      color: #4a5568;
      font-weight: 500;
      font-size: 1.05rem;
      transition: all 0.3s ease;
      position: relative;
      padding: 0.5rem 1.25rem;
      margin: 0 0.25rem;
    }

    .navbar-item::before {
      content: '';
      position: absolute;
      bottom: 0;
      left: 50%;
      width: 0;
      height: 2px;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      transform: translateX(-50%);
      transition: width 0.3s ease;
    }

    .navbar-item:hover {
      color: #667eea;
      transform: translateY(-2px);
    }

    .navbar-item:hover::before {
      width: 80%;
    }

    .navbar-item.is-active {
      color: #667eea;
      background: rgba(102, 126, 234, 0.08);
      border-radius: 8px;
    }

    /* Special button style for navbar */
    .navbar-item.button-nav {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      border-radius: 50px;
      padding: 0.5rem 1.5rem;
      margin-left: 1rem;
      font-weight: 600;
      box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
    }

    .navbar-item.button-nav:hover {
      background: linear-gradient(135deg, #5a67d8 0%, #6b46c1 100%);
      box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
      transform: translateY(-3px);
    }

    .navbar-item.button-nav.is-active {
      background: linear-gradient(135deg, #4c51bf 0%, #553c9a 100%);
      box-shadow: 0 8px 25px rgba(102, 126, 234, 0.5);
      transform: translateY(-3px) scale(1.05);
    }

    /* Add padding to body for fixed navbar */
    body {
      padding-top: 80px;
    }

    /* Enhanced Hero Section */
    .hero {
      background: linear-gradient(135deg, rgba(102, 126, 234, 0.03) 0%, rgba(118, 75, 162, 0.03) 100%);
      position: relative;
      overflow: hidden;
    }

    .hero::before {
      content: '';
      position: absolute;
      top: -50%;
      right: -50%;
      width: 200%;
      height: 200%;
      background: radial-gradient(circle, rgba(102, 126, 234, 0.05) 0%, transparent 70%);
      animation: float 20s ease-in-out infinite;
    }

    @keyframes float {
      0%, 100% { transform: translate(0, 0) rotate(0deg); }
      33% { transform: translate(-30px, -30px) rotate(120deg); }
      66% { transform: translate(30px, -30px) rotate(240deg); }
    }

    /* Enhanced Section Styles */
    .section {
      position: relative;
      padding: 5rem 1.5rem;
    }

    .section:nth-child(even) {
      background: linear-gradient(135deg, rgba(102, 126, 234, 0.02) 0%, rgba(118, 75, 162, 0.02) 100%);
    }

    /* Beautiful Cards */
    .beautiful-card {
      background: white;
      border-radius: 20px;
      box-shadow: 0 10px 40px rgba(0, 0, 0, 0.08);
      padding: 2rem;
      transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
      border: 1px solid rgba(102, 126, 234, 0.1);
    }

    .beautiful-card:hover {
      transform: translateY(-10px) scale(1.02);
      box-shadow: 0 20px 60px rgba(102, 126, 234, 0.15);
      border-color: rgba(102, 126, 234, 0.3);
    }

    /* Smooth scroll behavior */
    html {
      scroll-behavior: smooth;
    }

    /* Enhanced title styles */
    .title.is-1, .title.is-2, .title.is-3 {
      position: relative;
      display: inline-block;
    }

    .title.is-3::after {
      content: '';
      position: absolute;
      bottom: -10px;
      left: 50%;
      transform: translateX(-50%);
      width: 60px;
      height: 3px;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      border-radius: 2px;
    }

    /* Mobile menu styles */
    @media screen and (max-width: 1023px) {
      .navbar-burger {
        color: #667eea;
      }
      
      .navbar-burger:hover {
        background-color: rgba(102, 126, 234, 0.1);
      }
      
      .navbar-burger span {
        background-color: #667eea;
        height: 2px;
      }
      
      .navbar-menu.is-active {
        background: linear-gradient(135deg, rgba(255,255,255,0.98) 0%, rgba(249,250,251,0.98) 100%);
        box-shadow: 0 8px 30px rgba(0,0,0,0.1);
      }
    }

    /* Scroll to top button */
    .scroll-to-top {
      position: fixed;
      bottom: 30px;
      right: 30px;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      width: 50px;
      height: 50px;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      opacity: 0;
      visibility: hidden;
      transition: all 0.3s ease;
      z-index: 99;
      box-shadow: 0 4px 20px rgba(102, 126, 234, 0.3);
    }

    .scroll-to-top.visible {
      opacity: 1;
      visibility: visible;
    }

    .scroll-to-top:hover {
      transform: translateY(-5px);
      box-shadow: 0 8px 30px rgba(102, 126, 234, 0.4);
    }

  /* Custom styles for Evaluation Videos */
    .evaluation-video-card {
      background: #fff;
      border-radius: 12px;
      box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
      padding: 1.5rem;
      margin-bottom: 1.5rem;
      transition: all 0.3s ease;
      border: 1px solid #e8e8e8;
    }

    .evaluation-video-card:hover {
      transform: translateY(-5px);
      box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
    }

    .evaluation-video-container {
      border-radius: 8px;
      overflow: hidden;
      background: #f5f5f5;
      margin-bottom: 1rem;
    }

    .evaluation-video {
      width: 100%;
      height: auto;
      max-height: 280px;
      object-fit: cover;
      display: block;
      border-radius: 8px;
    }

    .evaluation-video-title {
      font-size: 1.1rem;
      font-weight: 600;
      color: #363636;
      text-align: center;
      margin: 0;
      padding: 0.5rem 0;
      border-top: 2px solid #f0f0f0;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      background-clip: text;
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      font-family: 'Google Sans', sans-serif;
    }

    #refresh-videos-btn {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      border: none;
      color: white;
      font-weight: 600;
      padding: 0.75rem 2rem;
      transition: all 0.3s ease;
      box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
    }

    #refresh-videos-btn:hover {
      transform: translateY(-2px);
      box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
      background: linear-gradient(135deg, #5a67d8 0%, #6b46c1 100%);
    }

    #refresh-videos-btn.is-loading {
      background: linear-gradient(135deg, #a0a0a0 0%, #808080 100%);
    }

    #refresh-videos-btn .icon {
      transition: transform 0.3s ease;
    }

    #refresh-videos-btn:hover .icon {
      transform: rotate(180deg);
    }

    #evaluation-videos-grid {
      margin-top: 2rem;
      min-height: 400px;
    }

    /* Responsive adjustments */
    @media screen and (max-width: 768px) {
      .evaluation-video-card {
        padding: 1rem;
        margin-bottom: 1rem;
      }
      
      .evaluation-video {
        max-height: 200px;
      }
      
      .evaluation-video-title {
        font-size: 1rem;
      }
      
      #refresh-videos-btn {
        padding: 0.6rem 1.5rem;
        font-size: 0.9rem;
      }
    }

    /* Loading animation for the grid */
    #evaluation-videos-grid.loading {
      opacity: 0.5;
      transition: opacity 0.3s ease;
    }

    /* Animation for video cards appearing */
    .evaluation-video-card {
      animation: fadeInUp 0.6s ease forwards;
    }

    @keyframes fadeInUp {
      from {
        opacity: 0;
        transform: translateY(30px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    /* Stagger animation for multiple cards */
    .column:nth-child(1) .evaluation-video-card {
      animation-delay: 0.1s;
    }

    .column:nth-child(2) .evaluation-video-card {
      animation-delay: 0.2s;
    }

    .column:nth-child(3) .evaluation-video-card {
      animation-delay: 0.3s;
    }

    /* Evaluation Videos Section Styling */
    .eval-tabs-container {
      margin-bottom: 2rem;
    }

    .eval-tabs-container .tabs {
      margin-bottom: 0;
    }

    .eval-tabs-container .tabs ul {
      border-bottom: 3px solid #e8e8e8;
    }

    .eval-tabs-container .tabs li a {
      color: #666;
      font-weight: 600;
      padding: 1rem 1.5rem;
      transition: all 0.3s ease;
      border-radius: 8px 8px 0 0;
    }

    .eval-tabs-container .tabs li:hover a {
      color: #667eea;
      background: rgba(102, 126, 234, 0.05);
    }

    .eval-tabs-container .tabs li.is-active a {
      color: #fff;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      border-bottom: 3px solid transparent;
    }

    .eval-tabs-container .tabs li.is-active a .icon i {
      color: #ffd700;
    }

    .level-content {
      padding: 2rem 0;
    }

    .level-subtitle {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      background-clip: text;
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      margin-bottom: 1rem !important;
      margin-top: 0.5rem !important;
      font-size: 1.5rem !important;
      line-height: 1.3 !important;
    }
    
    .level-content .subtitle.is-6 {
      margin-top: -0.5rem !important;
      margin-bottom: 2rem !important;
      color: #666;
      font-size: 1rem !important;
    }

    .eval-glide {
      margin-top: 2rem;
    }

    .eval-video-block {
      padding: 0 12px;
    }

    .eval-video-card {
      background: #fff;
      border-radius: 16px;
      box-shadow: 0 8px 30px rgba(0, 0, 0, 0.1);
      overflow: hidden;
      transition: all 0.4s ease;
      border: 2px solid transparent;
      height: 100%;
      display: flex;
      flex-direction: column;
    }

    .eval-video-card:hover {
      transform: translateY(-8px);
      box-shadow: 0 15px 40px rgba(102, 126, 234, 0.15);
      border-color: rgba(102, 126, 234, 0.3);
    }

    .eval-video-card video {
      width: 100%;
      height: 280px;
      object-fit: cover;
      display: block;
    }

    .eval-video-caption {
      padding: 1.2rem;
      margin: 0;
      font-weight: 600;
      font-size: 1.05rem;
      color: #363636;
      text-align: center;
      background: linear-gradient(135deg, rgba(102, 126, 234, 0.05) 0%, rgba(118, 75, 162, 0.05) 100%);
      flex-grow: 1;
      display: flex;
      align-items: center;
      justify-content: center;
    }

    /* Custom Glide arrows for evaluation carousels */
    .eval-glide .glide__arrow {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      border: none;
      width: 50px;
      height: 50px;
      border-radius: 50%;
      font-size: 20px;
      top: 50%;
      transform: translateY(-50%);
      box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
      transition: all 0.3s ease;
    }

    .eval-glide .glide__arrow:hover {
      background: linear-gradient(135deg, #5a67d8 0%, #6b46c1 100%);
      transform: translateY(-50%) scale(1.1);
      box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
    }

    .eval-glide .glide__arrow--left {
      left: -25px;
    }

    .eval-glide .glide__arrow--right {
      right: -25px;
    }

    /* Level difficulty indicators */
    .tabs li[data-level="L1"] .icon i:nth-child(1) { color: #ffb366; }
    .tabs li[data-level="L2"] .icon i:nth-child(1),
    .tabs li[data-level="L2"] .icon i:nth-child(2) { color: #ff8c42; }
    .tabs li[data-level="L3"] .icon i { color: #d2691e; }

    /* Responsive adjustments for evaluation section */
    @media screen and (max-width: 768px) {
      .eval-tabs-container .tabs li a {
        padding: 0.75rem 1rem;
        font-size: 0.9rem;
      }
      
      .eval-video-card video {
        height: 200px;
      }
      
      .eval-glide .glide__arrow {
        width: 40px;
        height: 40px;
        font-size: 16px;
      }
      
      .eval-glide .glide__arrow--left {
        left: -20px;
      }
      
      .eval-glide .glide__arrow--right {
        right: -20px;
      }
    }

    /* Animation for level content switching */
    .eval-content {
      min-height: 400px;
      position: relative;
    }

    .level-content {
      position: absolute;
      width: 100%;
      opacity: 0;
      visibility: hidden;
      transition: opacity 0.3s ease, visibility 0.3s ease;
    }

    .level-content.is-active {
      position: relative;
      opacity: 1;
      visibility: visible;
    }
    
    @keyframes fadeIn {
      from {
        opacity: 0;
        transform: translateY(20px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }
  </style>

</head>
<body>
  <!-- Beautiful Navigation Bar -->
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="container">
      <div class="navbar-brand">
        <a class="navbar-item navbar-brand" href="#home">
          ü§ñ MimicDroid
        </a>
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navbarMenu">
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>
      <div id="navbarMenu" class="navbar-menu">
        <div class="navbar-end">
          <a class="navbar-item" href="#home">Home</a>
          <a class="navbar-item" href="#abstract">Abstract</a>
          <a class="navbar-item" href="#demos">Demos</a>
          <a class="navbar-item" href="#method">Method</a>
          <a class="navbar-item" href="#experiments">Experiments</a>
          <a class="navbar-item" href="evaluation.html">Evaluation</a>
          <a class="navbar-item button-nav" href="#BibTeX">Cite</a>
        </div>
      </div>
    </div>
  </nav>

  <!-- Scroll to Top Button -->
  <div class="scroll-to-top" id="scrollToTop">
    <i class="fas fa-chevron-up"></i>
  </div>

  <section class="hero" id="home">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            
            <h1 class="title is-1 publication-title">MimicDroid: </h1>
            <h2 class="subtitle is-2 publication-subtitle">In-Context Learning for Humanoid Manipulation by Watching Humans</h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://shahrutav.github.io/" target="_blank">Rutav Shah</a>,</span>
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/harry-wang-16470a211/" target="_blank">Qi Wang</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="https://zhenyujiang.me/" target="_blank">Zhenyu Jiang</a><sup>*</sup>,</span>
                    <span class="author-block">
                    <a href="https://shuijing725.github.io/" target="_blank">Shuijing Liu</a><sup>*</sup>,</span>
                    <span class="author-block">
                  <a href="https://sateeshkumar21.github.io/" target="_blank">Sateesh Kumar</a>,</span>
                  <span class="author-block">
                    <a href="https://mingyoseo.com/" target="_blank"> Mingyo Seo</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://robertomartinmartin.com/" target="_blank">Roberto Mart√≠n-Mart√≠n</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://yukezhu.me/" target="_blank">Yuke Zhu</a>
                  </span>
                  </div>
                  <div class="is-size-5 publication-authors">

                    <span class="author-block">The University of Texas at Austin
                      <!-- <br>Conferance name and year -->
                    </span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution</small></span>
                  </div>
                  <br>
                    <div class="column has-text-centered">
                      <div class="publication-links">
                        <!-- PDF Link. -->
                        <span class="link-block">
                          <a href="."
                             class="external-link button is-normal is-rounded is-dark">
                            <span class="icon">
                                <i class="fas fa-file-pdf"></i>
                            </span>
                            <span>Paper</span>
                          </a>
                        </span>
                        <!--arXiv Link.-->
                        <span class="link-block">
                          <a
                            href="."
                            class="external-link button is-normal is-rounded is-dark"
                          >
                            <span class="icon">
                              <i class="ai ai-arxiv"></i>
                            </span>
                            <span>arXiv</span>
                          </a>
                        </span>
                        <!-- Video Link. -->
                        <!-- <span class="link-block">
                          <a href="https://www.youtube.com/watch?v=ts0e2HHp3Lk"
                             class="external-link button is-normal is-rounded is-dark">
                            <span class="icon">
                                <i class="fab fa-youtube"></i>
                            </span>
                            <span>Video</span>
                          </a>
                        </span> -->
                        <!-- Code Link. -->
                        <span class="link-block">
                          <a href="."
                             class="external-link button is-normal is-rounded is-dark">
                            <span class="icon">
                                <i class="fab fa-github"></i>
                            </span>
                            <span>Code (Coming Soon)</span>
                            </a>
                        </span>
                        <!-- Dataset Link. -->
                        <!-- <span class="link-block">
                          <a href="https://drive.google.com/drive/folders/1mNJmnyzIoCudRcTdRVrN3WAiuWIM8355"
                             class="external-link button is-normal is-rounded is-dark">
                            <span class="icon">
                                <i class="far fa-images"></i>
                            </span>
                            <span>Dataset</span>
                            </a> -->
                      </div>
                    </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Abstract 
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">    
    <div class="column is-four-fifths">
  <!-- <div class="content " style="background:#f0f0f0; padding:20px 24px; border:1px solid #ccc; border-radius:6px;">
  <p style="margin:0;">
     <strong>TL;DR:</strong> We present <strong>COLLAGE</strong>, a few-shot imitation learning method that fuses data subsets retrieved from large-scale datasets using multiple measures of similarity to the target task. It scores each subset by training an imitation learning policy on it, measuring how likely it is to produce the target actions, and uses these scores to prioritize the most effective data during training.
  </p>
</div>
    </div>
    </div>
    </div>
    </div>
  </div>-->

  <section class="section" id="abstract">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="beautiful-card">
            <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">  
            <p>
              We envision humanoids that can efficiently adapt to new tasks, achieving few-shot manipulation in ever-changing environments. In-context learning (ICL) is a promising framework to achieve this goal, but existing ICL approaches typically rely on costly teleoperated datasets or limited expressivity of simulations for training. In this work, we propose using human play videos‚Äîcontinuous, unlabeled videos of people interacting freely with their environment by their curiosity‚Äîas a scalable and diverse data source. Learning from human play videos poses two key challenges: (i) the absence of labeled data to train policies to learn in-context; (ii) the embodiment gap between humans and humanoids. We introduce MimicDroid, a method that enables humanoids to perform ICL by using only human play videos as training data. To overcome the lack of supervision, MimicDroid extracts trajectory pairs exhibiting similar manipulation behaviors in a self-supervised manner, e.g., ‚Äúplacing the bread on the oven tray,‚Äù and ‚Äúplacing a bagel on the oven tray.‚Äù The policy is trained to predict actions of one trajectory, conditioned on others with similar manipulation behaviors. This trains the model to learn in-context from the provided examples. To address the embodiment gap, first, MimicDroid retargets human wrist poses estimated from RGB videos to the humanoid, leveraging their kinematic similarity. Second, to handle the visual gap, it applies random patch masking during training to prevent overfitting to human-specific cues. To systematically evaluate few-shot learning for humanoids, we introduce an open-source simulation benchmark with three levels of increasing generalization difficulty from seen to unseen objects and environments. In both simulation and the real world, MimicDroid outperforms state-of-the-art methods, achieving nearly twofold better generalization to novel objects in the real world.
            </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


    <!-- Rollout Carousel -->
  <section class="section" id="demos">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Policy Rollouts with MimicDroid</h2>
      <figure>
      <div class="glide" style="position: relative;">
        <div class="glide__track" data-glide-el="track">
          <ul class="glide__slides">
            <li class="glide__slide"><div class="video-block"><div class="video-card"><video autoplay muted loop playsinline controls><source src="./static/videos/potatoes_basket.mp4" type="video/mp4" /></video></div><p class="video-caption">Potatoes-Basket</p></div></li>
            <li class="glide__slide"><div class="video-block"><div class="video-card"><video autoplay muted loop playsinline controls><source src="./static/videos/demo_oven_plate_chips.mp4" type="video/mp4" /></video></div><p class="video-caption">Chips-Plate</p></div></li>
            <li class="glide__slide"><div class="video-block"><div class="video-card"><video autoplay muted loop playsinline controls><source src="./static/videos/demo_rotating_disk.mp4" type="video/mp4" /></video></div><p class="video-caption">Cookies-Plate</p></div></li>
            <li class="glide__slide"><div class="video-block"><div class="video-card"><video autoplay muted loop playsinline controls><source src="./static/videos/demo_rotating_disk_plate.mp4" type="video/mp4" /></video></div><p class="video-caption">Bread-Plate</p></div></li>
            <li class="glide__slide"><div class="video-block"><div class="video-card"><video autoplay muted loop playsinline controls><source src="./static/videos/strawberries_to_plate.mp4" type="video/mp4" /></video></div><p class="video-caption">Strawberries-Oven</p></div></li>
            <li class="glide__slide"><div class="video-block"><div class="video-card"><video autoplay muted loop playsinline controls><source src="./static/videos/bread_on_oven_tray.mp4" type="video/mp4" /></video></div><p class="video-caption">Bread-Tray</p></div></li>
          </ul>
        </div>
        <div class="glide__arrows" data-glide-el="controls">
          <button class="glide__arrow glide__arrow--left" data-glide-dir="<">‚Äπ</button>
          <button class="glide__arrow glide__arrow--right" data-glide-dir=">">‚Ä∫</button>
        </div>
        <div class="glide__bullets" data-glide-el="controls[nav]">
          <button class="glide__bullet" data-glide-dir="=0"></button>
          <button class="glide__bullet" data-glide-dir="=1"></button>
          <button class="glide__bullet" data-glide-dir="=2"></button>
          <button class="glide__bullet" data-glide-dir="=3"></button>
          <button class="glide__bullet" data-glide-dir="=4"></button>
          <button class="glide__bullet" data-glide-dir="=5"></button>
        </div>
      </div>
      <!-- <figcaption class="has-text-centered" style="margin-top: 1rem;">.</figcaption> -->
        
    </figure>
    </div>
  </section> 


  <section class="section">
    <div class="container is-max-desktop has-text-centered">
      <h2 class="title is-3">Video</h2>
      <p class="is-6" style="margin-bottom: 1rem;">
        Watch the video to see MimicDroid in action!
      </p>
      <video
        controls
        preload="metadata"
        style="max-width:100%; border-radius:8px;"
      >
        <source src="./static/images/summary_video.mp4" type="video/mp4" />
        Your browser does not support the video tag.
      </video>
    </div>
  </section>

  <!-- Method Overview -->
  <section class="section" id="method">
  <div class="container is-max-desktop has-text-centered">
    <h2 class="title is-3">Method Overview</h2>
    <figure class="image">
      <img src="./static/images/mew_method_figurev2-1.png" 
           alt="Overview of MIMICDROID" />
          
      <figcaption class="method-caption has-text-justified">
        <strong>Overview of MimicDroid.</strong> MimicDroid performs meta-training for in-context learning (Meta-ICL) by constructing context-target pairs from human play videos.
    For a target segment, we retrieve the top-k most similar trajectory segments (top-left) based on observation-action similarity (top-right) to serve as context.
    These context-target pairs are used to teach the policy in-context learning (bottom-left). To overcome the human-robot visual gap and avoid overfitting to human-specific visual cues, we apply visual masking to input images (bottom-right), improving transferability.
      </figcaption>
    </figure>
  </div>
</section>

  

  <!-- Experiments -->
   <section class="section" id="experiments">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-3">Experiments</h2>
          <div class="content">
            <figure class="image">
              <img src="./static/images/results.png" alt="experiment results" />
              <figcaption>
               <p>Success rates of MimicDroid in the simulation benchmark, comparing both the Abstract and GR1 embodiments across levels of generalization difficulty (L1‚ÄìL3). MimicDroid consistently outperforms prior approaches and ablations, demonstrating strong transfer from human play videos to humanoid control.</p>
              </figcaption>
            </figure>
            <h3 class="title is-4" style="margin-top: 1.5em;">Quantitative Results</h3>
            
            <div class="columns is-multiline is-centered">
              <figure class="image">
                <div class="columns is-multiline is-centered">
                  <div class="column is-one-third">
                    <img src="./static/images/n_prompts-1.png" alt="Number of Prompts Results" />
                  </div>
                  <div class="column is-one-third">
                    <img src="./static/images/n_topk-1.png" alt="Top-K Results" />
                  </div>
                  <div class="column is-one-third">
                    <img src="./static/images/success_vs_frames-1.png" alt="Success vs Frames" />
                  </div>
                </div>
                <figcaption>Quantitative ablations of MimicDroid. Left: Performance as a function of the number of test-time in-context demonstrations. Middle: Effect of the number of retrieved top-k context segments used during training. Right: Scaling behavior as the amount of training video data (frames) increases. These results highlight that MimicDroid benefits from more context at test time, an appropriate retrieval budget at training time, and larger play video datasets.</figcaption>
              </figure>
            </div>

            <h3 class="title is-4" style="margin-top: 1.5em;">Qualitative Analysis</h3>
            <figure class="image">
              <img src="./static/images/mew_rw_figure-1.png" alt="Qualitative Method Overview" />
              <figcaption>Real-world qualitative rollouts of MimicDroid. The humanoid GR1 successfully adapts to novel objects and environments using only a few human video demonstrations at test time. Examples include placing food items on trays, transferring them into containers, and interacting with household appliances. These case studies illustrate the method‚Äôs ability to generalize across tasks and embodiments from purely video-based training.</figcaption>
            </figure>

        </div>
      </div>
      </div>
    </div>
    </section>

            <!-- <h3 class="title is-4" style="margin-top: 1.5em;">GR1 Embodiment</h3>
            <figure class="image">
              <img src="./static/images/real_world_results.png" alt="Real-world experiment results" />
              <figcaption>
                Real-world evaluation on six manipulation tasks using the DROID dataset. For each task, we use only <strong>5 target demonstrations</strong> and retrieve from a pool of 30k successful episodes. COLLAGE achieves an average success rate of 6.83/15, representing a <strong>58% relative performance improvement over STRAP (4.33/15) </strong> and a <strong> 64% improvement over LANG (4.16/15)</strong>. Policies trained solely on the 5 in-domain demonstrations (no retrieval) achieve only 1.00/15 success on average. In contrast, COLLAGE effectively leverages relevant demonstrations from DROID to significantly boost policy performance.
              </figcaption>
            </figure>
          </div>
        </div>
      </div>
    </div> -->
  </section>
    <!-- Weights Predicted by COLLAGE -->
<!-- <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Importance Weights Predicted by COLLAGE</h2>
      <div class="has-text-centered">
        <figure class="image" style="max-width: 950px; width: 100%; margin: 0 auto;">
          <img src="./static/images/modality_weights_pie_chart.png" alt="Modality Weights Pie Chart" style="width: 100%; height: auto; border-radius: 8px;">
          <figcaption style="margin-top: 0.75rem; font-size: 1rem; color: #444;">
            <figcaption style="margin-top: 0.75rem;">
                Importance weights assigned by <strong>COLLAGE</strong> to different modalities used in our framework (Visual, Motion, Shape, Language).              
          </figcaption>
        </figure>
      </div>
    </div>
  </section> -->


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{shah2025mimicdroid,
  title={MimicDroid: In-Context Learning for Humanoid Manipulation by Watching Humans},
  author={Shah, Rutav and Wang, Qi and Jiang, Zhenyu and Liu, Shuijing and Kumar, Sateesh and Seo, Mingyo and Mart{\'\i}n-Mart{\'\i}n, Roberto and Zhu, Yuke},
  journal={arXiv preprint arXiv:},
  year={2025}
}
      </code></pre>
    </div>
</section>
  <!-- SCRIPTS -->
  <script>
    // Navigation functionality
    document.addEventListener('DOMContentLoaded', function() {
      // Burger menu for mobile
      const burger = document.querySelector('.navbar-burger');
      const menu = document.getElementById('navbarMenu');
      
      if (burger) {
        burger.addEventListener('click', () => {
          burger.classList.toggle('is-active');
          menu.classList.toggle('is-active');
        });
      }
      
      // Navbar scroll effect
      const navbar = document.querySelector('.navbar');
      window.addEventListener('scroll', () => {
        if (window.scrollY > 50) {
          navbar.classList.add('scrolled');
        } else {
          navbar.classList.remove('scrolled');
        }
      });
      
      // Scroll to top button
      const scrollToTop = document.getElementById('scrollToTop');
      window.addEventListener('scroll', () => {
        if (window.scrollY > 300) {
          scrollToTop.classList.add('visible');
        } else {
          scrollToTop.classList.remove('visible');
        }
      });
      
      scrollToTop.addEventListener('click', () => {
        window.scrollTo({ top: 0, behavior: 'smooth' });
      });
      
      // Active navigation link based on scroll position
      const sections = document.querySelectorAll('section[id]');
      const navLinks = document.querySelectorAll('.navbar-item');
      
      window.addEventListener('scroll', () => {
        let current = '';
        sections.forEach(section => {
          const sectionTop = section.offsetTop - 100;
          if (window.scrollY >= sectionTop) {
            current = section.getAttribute('id');
          }
        });
        
        navLinks.forEach(link => {
          link.classList.remove('is-active');
          if (link.getAttribute('href') === '#' + current) {
            link.classList.add('is-active');
          }
        });
      });
      
      // Handle cite button click state
      const citeButton = document.querySelector('a[href="#BibTeX"]');
      if (citeButton) {
        citeButton.addEventListener('click', function() {
          // Remove active state from all nav items
          navLinks.forEach(link => {
            link.classList.remove('is-active');
          });
          // Add active state to cite button temporarily
          this.classList.add('is-active');
          
          // Remove active state after a delay to show the click feedback
          setTimeout(() => {
            this.classList.remove('is-active');
          }, 1000);
        });
      }
      
      // Smooth scroll for navigation links
      document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener('click', function (e) {
          if (this.getAttribute('href') === '#') return;
          e.preventDefault();
          const target = document.querySelector(this.getAttribute('href'));
          if (target) {
            target.scrollIntoView({ behavior: 'smooth', block: 'start' });
          }
        });
      });
    });
  </script>


<!-- <section class="section">
  <div class="container is-max-desktop has-text-centered">
    <h2 class="title is-3">Why use multiple feature modalities for retrieval?</h2>
    <p class="subtitle is-6">
      Below, we illustrate the benefits of leveraging on multiple modalities for data retrieval and using COLLAGE to fuse them.
    </p> 

    <!-- Book Place task -->
<!--    <p class="subtitle is-6">
      Retrieved data for the task of <strong>Place the Book in the Back Compartment of the Caddy</strong>.
    </p>
    <figure class="image" style="margin-bottom: 2rem;">
      <img
        src="./static/images/book_caddy_4feats.png"
        alt="Retrieved data for Book Place task"
        style="max-width:100%;"
      />
      <figcaption>
        <!-- Although the instruction <strong>‚ÄúPlace the Book in the Back Compartment of the Caddy‚Äù</strong> matches exactly, visual-only retrieval from the prior dataset misses these segments due to appearance differences.
        For this task, the target demonstration involves placing the book in the back compartment of a caddy. The prior dataset contains two helpful types of segments: (1) those with the same scene but a different end-pose, where the book is placed in the front compartment‚Äîthese are reliably retrieved using visual similarity; and (2) those with the same task but different scene appearance, where the book is correctly placed in the back compartment but the visual context differs‚Äîthese are primarily retrieved using motion and language cues. Since each modality recovers complementary subsets of relevant data, fusing them in COLLAGE raises accuracy from 66.00 % (visual only) to 89.33 %, yielding an absolute gain of 23.33 percentage points.
    </figcaption>
    </figure> 

    <!-- Cheese Butter task 
    <p class="subtitle is-6">
      Retrieved data for the task of <strong>Put Both the Cream Cheese Box and the Butter in the Basket</strong>.
    </p>
    <figure class="image">
      <img
        src="./static/images/cheese_butter_4feats.png"
        alt="Retrieved data for Cheese Butter task"
        style="max-width:100%;"
      />
      <figcaption>
        In the Cheese Butter task, shape-based retrieval from the prior dataset retrieves far more examples from ‚ÄúPick up Butter..‚Äù and ‚ÄúPick up Tomato Sauce..‚Äù than visual- or motion-based retrieval. These segments provide direct, task-relevant demonstrations of placing similarly shaped objects into the basket. Consequently, the shape modality outperforms both visual and motion, and COLLAGE assigns it the highest weight‚Äîyielding performance on par with shape-only retrieval.
      </figcaption>
    </figure>
  </div>
</section> -->


  <!-- Footer -->
  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <p>
          This website is based on the <a href="https://nerfies.github.io/">Nerfies</a> website template,
          licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
        </p>
      </div>
    </div>
  </footer>

  <!-- Glide JS -->
  <script src="https://cdn.jsdelivr.net/npm/@glidejs/glide@3.6.0/dist/glide.min.js"></script>
  <script>
    window.addEventListener('load', function () {
      // Initialize main policy rollouts carousel
      new Glide('.glide', {
        type: 'carousel',
        rewind: false,
        perView: 3,
        focusAt: 'center',
        gap: 24,
        breakpoints: {
          1024: { perView: 2 },
          768: { perView: 1 }
        }
      }).mount();


    });


  </script>


</body>
</html>
